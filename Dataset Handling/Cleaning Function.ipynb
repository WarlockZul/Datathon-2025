{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62041ef9",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75aaefc8",
   "metadata": {},
   "source": [
    "________________________________________\n",
    "### 1. Initialize libraries and load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35436276",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import zscore\n",
    "\n",
    "# Load dataset excluding the modified columns\n",
    "df = pd.read_excel(\n",
    "    \"Dirty_Dataset_with_Log.xlsx\",\n",
    "    usecols=lambda col: col not in [\"DIY\"]\n",
    ")\n",
    "\n",
    "print(\"Dataset loaded successfully.\")\n",
    "display(df.head())\n",
    "\n",
    "# Dataset shape\n",
    "print(f\"Number of Rows: {df.shape[0]}\")\n",
    "print(f\"Number of Columns: {df.shape[1]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f1d969",
   "metadata": {},
   "source": [
    "_______________\n",
    "### 2. Find Redundant Data based on the same values in the row and remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0461b80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify FULL duplicates (entire row is identical)\n",
    "full_duplicates = df[df.duplicated(keep=False)]\n",
    "\n",
    "print(\"\\nFULL redundant rows:\")\n",
    "display(full_duplicates)\n",
    "\n",
    "# Remove only TRUE duplicates (entire row same)\n",
    "df_missing = df.drop_duplicates(keep=\"first\").reset_index(drop=True)\n",
    "\n",
    "print(\"\\nAfter removing redundant rows:\", df_missing.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb052eb5",
   "metadata": {},
   "source": [
    "_____________\n",
    "### 3. Missing Values Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541fc51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_rows = df_missing[df_missing.isna().any(axis=1)].copy()\n",
    "\n",
    "# Identify which columns are missing in each row\n",
    "missing_rows[\"missing_columns\"] = missing_rows.apply(\n",
    "    lambda row: [col for col in df_missing.columns if pd.isna(row[col])],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Show only key columns\n",
    "missing_info = missing_rows[[\"vehicle_id\", \"timestamp\", \"missing_columns\"]]\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "display(missing_info)\n",
    "pd.reset_option('display.max_rows')\n",
    "pd.reset_option('display.max_columns')\n",
    "\n",
    "total_missing = df_missing.isna().sum().sum()\n",
    "print(\"Total missing values in cleaned dataset:\", total_missing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f48441",
   "metadata": {},
   "source": [
    "_______________\n",
    "# Fill in Missing Values using KNN imputations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d378bf9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "int_cols = [\n",
    "    \"lidar_points\",\n",
    "    \"radar_objects\",\n",
    "    \"camera_objects\",\n",
    "    \"latency_ms\",\n",
    "    \"throughput_kbps\",\n",
    "    \"collision_detected\"\n",
    "]\n",
    "\n",
    "float_cols = [\n",
    "    \"gps_latitude\",\n",
    "    \"gps_longitude\",\n",
    "    \"packet_drop_rate\",\n",
    "    \"packet_delivery_ratio\",\n",
    "    \"obstacle_detection_accuracy\",\n",
    "    \"decision_accuracy\"\n",
    "]\n",
    "\n",
    "# Combine for KNN processing\n",
    "numeric_cols = int_cols + float_cols\n",
    "\n",
    "print(\"Integer columns:\", int_cols)\n",
    "print(\"Float columns:\", float_cols)\n",
    "\n",
    "# Create a copy for KNN\n",
    "df_knn = df_missing.copy()\n",
    "\n",
    "# --- Run KNN ---\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "\n",
    "df_knn[numeric_cols] = imputer.fit_transform(df_knn[numeric_cols])\n",
    "\n",
    "# --- Restore the correct data types ---\n",
    "\n",
    "# Convert integer columns back to whole numbers\n",
    "for col in int_cols:\n",
    "    df_knn[col] = df_knn[col].round().astype(int)\n",
    "\n",
    "# Float columns remain float (no change needed)\n",
    "\n",
    "# Save final dataset\n",
    "df_knn.to_csv(\"Cleaned_Dataset.csv\", index=False)\n",
    "print(\"KNN-filled dataset saved as Cleaned_Dataset.csv.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e6b2e0",
   "metadata": {},
   "source": [
    "# Write report of the filled value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4bdedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Identify missing locations BEFORE imputation\n",
    "missing_locs = []\n",
    "for row in df_missing.index:\n",
    "    for col in numeric_cols:\n",
    "        if pd.isna(df_missing.loc[row, col]):\n",
    "            missing_locs.append((row, col))\n",
    "\n",
    "# 2. Create a results table\n",
    "results = []\n",
    "\n",
    "for row, col in missing_locs:\n",
    "    filled = df_knn.loc[row, col]   # value after KNN imputation\n",
    "    \n",
    "    results.append({\n",
    "        \"row_index\": row,\n",
    "        \"vehicle_id\": df_missing.loc[row, \"vehicle_id\"],\n",
    "        \"timestamp\": df_missing.loc[row, \"timestamp\"],\n",
    "        \"column_imputed\": col,\n",
    "        \"filled_value\": filled\n",
    "    })\n",
    "\n",
    "# 3. Convert to DataFrame for display\n",
    "imputation_report = pd.DataFrame(results)\n",
    "\n",
    "print(\"KNN Imputation Report (Before vs After):\")\n",
    "display(imputation_report)\n",
    "\n",
    "# Save report\n",
    "imputation_report.to_csv(\"KNN_Imputed_Values_Report.csv\", index=False)\n",
    "print(\"Saved: KNN_Imputed_Values_Report.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f2ace1",
   "metadata": {},
   "source": [
    "____________\n",
    "# Information of Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329cc1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Cleaned Dataset Info:\")\n",
    "df_knn.info()\n",
    "\n",
    "print(\"\\nSummary Statistics:\")\n",
    "display(df_knn.describe())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
